{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harivarshith/NLP-Assignments-1351/blob/main/14_11_25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWm9icEKtpPo",
        "outputId": "df5323e6-7e83-4cbd-d9c7-8f5ae79173e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from gensim.models import Word2Vec\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "data = {\n",
        "    'clean_text': [\n",
        "        'fire near la pray affected', 'saw new movie disaster lol',\n",
        "        'flood warning issued new york city', 'phone slow today throw out',\n",
        "        'earthquake rocks japan damage widespread', 'new album fire cant stop listening',\n",
        "        'tornado hit oklahoma emergency needed', 'check cool website',\n",
        "    ],\n",
        "    'target': [1, 0, 1, 0, 1, 0, 1, 0]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "sentences = [text.split() for text in df['clean_text']]\n",
        "\n",
        "\n",
        "def get_word2vec_embeddings(sentences, vector_size=100):\n",
        "    \"\"\"Trains Word2Vec and averages word vectors for sentence embedding.\"\"\"\n",
        "    w2v_model = Word2Vec(sentences, vector_size=vector_size, window=5, min_count=1, workers=4)\n",
        "    sentence_embeddings = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        vectors = [w2v_model.wv[word] for word in sentence if word in w2v_model.wv]\n",
        "        if vectors:\n",
        "            sentence_embeddings.append(np.mean(vectors, axis=0))\n",
        "        else:\n",
        "            sentence_embeddings.append(np.zeros(vector_size))\n",
        "\n",
        "    return np.array(sentence_embeddings)\n",
        "\n",
        "def get_bert_embeddings(texts):\n",
        "    \"\"\"Extracts BERT [CLS] token embeddings (sentence embedding).\"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "    model = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=64)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state[:, 0, :].numpy()\n",
        "\n",
        "w2v_embeddings = get_word2vec_embeddings(sentences, vector_size=100)\n",
        "print(f\"Word2Vec Embeddings Shape: {w2v_embeddings.shape}\")\n",
        "\n",
        "bert_embeddings = get_bert_embeddings(df['clean_text'].tolist())\n",
        "print(f\"BERT Embeddings Shape: {bert_embeddings.shape}\")\n",
        "\n",
        "elmo_embeddings = np.random.rand(*w2v_embeddings.shape)\n",
        "print(f\"ELMo Embeddings Shape (Simulated): {elmo_embeddings.shape}\")\n",
        "\n",
        "\n",
        "\n",
        "def visualize_embeddings(embeddings, title, labels):\n",
        "    \"\"\"Applies t-SNE directly on the embeddings and plots the 2D results.\"\"\"\n",
        "\n",
        "    n_samples = embeddings.shape[0]\n",
        "    safe_perplexity = min(5, n_samples - 1)\n",
        "\n",
        "\n",
        "    print(f\"Applying t-SNE on {title} with perplexity={safe_perplexity}...\")\n",
        "\n",
        "    tsne = TSNE(n_components=2, random_state=42, perplexity=safe_perplexity)\n",
        "    embeddings_2d = tsne.fit_transform(embeddings)\n",
        "\n",
        "    df_plot = pd.DataFrame(embeddings_2d, columns=['x', 'y'])\n",
        "    df_plot['label'] = labels\n",
        "    df_plot['class'] = df_plot['label'].apply(lambda x: 'Disaster' if x == 1 else 'Non-Disaster')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.scatterplot(\n",
        "        x='x', y='y',\n",
        "        hue='class',\n",
        "        data=df_plot,\n",
        "        palette=['red', 'blue'],\n",
        "        alpha=0.8\n",
        "    )\n",
        "    plt.title(f'2D t-SNE Visualization: {title}')\n",
        "    plt.legend(title='Tweet Class')\n",
        "    plt.show()\n",
        "\n",
        "labels = df['target'].values\n",
        "visualize_embeddings(w2v_embeddings, \"Word2Vec Embeddings\", labels)\n",
        "visualize_embeddings(elmo_embeddings, \"ELMo Embeddings (Simulated)\", labels)\n",
        "visualize_embeddings(bert_embeddings, \"BERT Embeddings\", labels)"
      ]
    }
  ]
}